---------------------------------------------------------------------------

clc;
clear all;
P_XY=input('enter joint probability matrix');
[m,n]=size(P_XY);

 for i=1:m
 px(i)=0;
 for j=1:n
px(i)=px(i)+P_XY(i,j);
 end
end
disp('P(X) matrix is:')
disp(px);
hx=sum(-px.*log2(px));
disp('input entropy H(X) is:')
disp(hx);

for i=1:n
    py(i)=0;
    for j=1:m
        py(i)=py(i)+P_XY(j,i);
       end 
   end
   disp('P(Y) matrix is:')
   disp(py);
    hy=sum(-py.*log2(py));
    disp('Output entropy H(Y) is:')
    disp(hy);
    
    h_xy=0;
     for i=1:m
         for j=1:n
             h_xy=h_xy+P_XY(i,j)* log2(1/P_XY(i,j));
         end 
     end
     disp('entropy H(XY) is :')
     disp(h_xy);
     hxby=h_xy+hy;
     hybx=h_xy-hx;
     disp(' conditional entropy;');
     disp(hxby);
     disp(hybx);
     ixy=hx+hy-h_xy;
     disp('mutual information I(X,Y)is:')
     disp(ixy);

-----------------------------------------------------------------------------